{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":67356,"databundleVersionId":8006601,"sourceType":"competition"}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# for basic SMILES operations, descriptors and fingerprints\n!pip install -q rdkit-pypi\n\n# for graphs\n!pip install -q dgl\n\n# for mol2vec\n!pip install -q mol2vec\n\n!pip install duckdb\n\n!pip install faiss-gpu","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-07T04:14:23.727110Z","iopub.execute_input":"2024-07-07T04:14:23.727736Z","iopub.status.idle":"2024-07-07T04:15:37.265874Z","shell.execute_reply.started":"2024-07-07T04:14:23.727701Z","shell.execute_reply":"2024-07-07T04:15:37.264944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    'num_samples_per_class': 10000,  # Adjust as needed\n    'ecfp_radius': 3,\n    'ecfp_bits': 1024,\n    'batch_size': 32,  # Increase batch size if you have more GPU memory\n    'train_test_split_ratio': 0.2,\n    'molformer_model_name': 'ibm/MoLFormer-XL-both-10pct',\n    'use_gpu_for_faiss': True,\n    'early_stopping_rounds': 10,  # Add early stopping rounds\n    'rf_params': {\n        'n_estimators': 250,  # Increase number of trees\n        'max_depth': 9,\n        'random_state': 42,\n        'n_jobs': -1\n    },\n    'xgb_params': {\n        'n_estimators': 250,  # Increase number of boosting rounds\n        'max_depth': 6,\n        'learning_rate': 0.1,\n        'subsample': 0.8,\n        'colsample_bytree': 0.8,\n        'random_state': 42\n    }\n}\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import duckdb\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\ndef load_and_prepare_data(config):\n    # Load and balance dataset\n    train_path = '/kaggle/input/leash-BELKA/train.parquet'\n    con = duckdb.connect()\n\n    df = con.query(f\"\"\"\n        (SELECT *\n         FROM parquet_scan('{train_path}')\n         WHERE binds = 0\n         ORDER BY random()\n         LIMIT {config['num_samples_per_class']})\n        UNION ALL\n        (SELECT *\n         FROM parquet_scan('{train_path}')\n         WHERE binds = 1\n         ORDER BY random()\n         LIMIT {config['num_samples_per_class']})\n    \"\"\").df()\n\n    con.close()\n\n    # Combine SMILES strings\n    df['combined_smiles'] = df['molecule_smiles'] + ' ' + df['buildingblock1_smiles'] + ' ' + df['buildingblock2_smiles'] + ' ' + df['buildingblock3_smiles']\n\n    # One-hot encode the protein_name\n    onehot_encoder = OneHotEncoder(sparse_output=False)\n    protein_onehot = onehot_encoder.fit_transform(df[['protein_name']])\n    df['protein_onehot'] = list(protein_onehot)\n\n    # Convert SMILES to RDKit molecules\n    df['molecule'] = df['molecule_smiles'].apply(Chem.MolFromSmiles)\n\n    # Function to generate ECFP fingerprints\n    def generate_ecfp(molecule, radius=config['ecfp_radius'], bits=config['ecfp_bits']):\n        if molecule is None:\n            return [0] * bits\n        return list(AllChem.GetMorganFingerprintAsBitVect(molecule, radius, nBits=bits))\n\n    # Generate ECFPs\n    df['ecfp'] = df['molecule'].apply(lambda x: generate_ecfp(x, config['ecfp_radius'], config['ecfp_bits']))\n\n    # Load pre-trained MolFormer model and tokenizer\n    mf_tokenizer = AutoTokenizer.from_pretrained(config['molformer_model_name'], deterministic_eval=True, trust_remote_code=True)\n    mf_model = AutoModelForSequenceClassification.from_pretrained(config['molformer_model_name'], num_labels=2, trust_remote_code=True)\n    mf_model.eval()\n\n    # Tokenize SMILES and get embeddings\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    mf_model.to(device)\n    \n    def get_molformer_embeddings(smiles):\n        inputs = mf_tokenizer(smiles, padding=True, truncation=True, return_tensors=\"pt\")\n        inputs = {key: val.to(device) for key, val in inputs.items()}  # Ensure all inputs are on the same device\n        with torch.no_grad():\n            outputs = mf_model(**inputs)\n        return outputs.logits.cpu().numpy().flatten()\n\n    df['molformer_embeddings'] = df['combined_smiles'].apply(get_molformer_embeddings)\n\n    # Combine ECFPs and MolFormer embeddings\n    def combine_features(ecfp, molformer, protein_onehot):\n        return np.concatenate([ecfp, molformer, protein_onehot])\n\n    df['hybrid_embeddings'] = df.apply(lambda row: combine_features(row['ecfp'], row['molformer_embeddings'], row['protein_onehot']), axis=1)\n\n    # Create the enhanced_smiles column by concatenating the combined SMILES and the protein_onehot encoding as a string\n    protein_str = [' '.join(map(str, row)) for row in df['protein_onehot']]\n    df['enhanced_smiles'] = df['combined_smiles'] + ' ' + protein_str\n\n    return df, onehot_encoder\n\n# Load and prepare data\ndf, onehot_encoder = load_and_prepare_data(config)\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T04:32:03.496680Z","iopub.execute_input":"2024-07-07T04:32:03.497058Z","iopub.status.idle":"2024-07-07T04:32:51.388117Z","shell.execute_reply.started":"2024-07-07T04:32:03.497029Z","shell.execute_reply":"2024-07-07T04:32:51.387133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import faiss\nimport numpy as np\nimport torch\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score\nfrom sklearn.model_selection import StratifiedKFold, learning_curve, train_test_split\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# Function to generate ECFP\ndef generate_ecfp(molecule, radius, bits):\n    if molecule is None:\n        return [0] * bits\n    return list(AllChem.GetMorganFingerprintAsBitVect(molecule, radius, nBits=bits))\n\n# Function to get MolFormer embeddings in batches\ndef get_molformer_embeddings_batch(smiles_list, tokenizer, model, device):\n    inputs = tokenizer(smiles_list, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n    inputs = {key: val.to(device) for key, val in inputs.items()}  # Move inputs to the same device as the model\n    with torch.no_grad():\n        outputs = model(**inputs)\n    embeddings = outputs.logits.cpu().numpy()\n    return embeddings\n\n# Function to generate features for both training and submission\ndef generate_features(df, onehot_encoder, config, tokenizer, model, device):\n    df['combined_smiles'] = df['molecule_smiles'] + ' ' + df['buildingblock1_smiles'] + ' ' + df['buildingblock2_smiles'] + ' ' + df['buildingblock3_smiles']\n\n    # Generate ECFPs for the molecule_smiles\n    df['molecule'] = df['molecule_smiles'].apply(Chem.MolFromSmiles)\n    df['ecfp'] = df['molecule'].apply(lambda x: generate_ecfp(x, config['ecfp_radius'], config['ecfp_bits']))\n\n    # One-hot encode the protein_name\n    protein_onehot = onehot_encoder.transform(df[['protein_name']])\n    protein_onehot_df = pd.DataFrame(protein_onehot, index=df.index)\n\n    # Get MolFormer embeddings for combined SMILES in batches\n    combined_smiles_list = df['combined_smiles'].tolist()\n    molformer_embeddings_list = []\n\n    for i in range(0, len(combined_smiles_list), config['batch_size']):\n        batch_smiles = combined_smiles_list[i:i + config['batch_size']]\n        molformer_embeddings_list.extend(get_molformer_embeddings_batch(batch_smiles, tokenizer, model, device))\n\n    df['molformer_embeddings'] = molformer_embeddings_list\n\n    # Combine ECFPs, MolFormer embeddings, and one-hot encoded protein names\n    df['hybrid_embeddings'] = df.apply(\n        lambda row: np.concatenate([row['ecfp'], row['molformer_embeddings'], protein_onehot_df.loc[row.name]]), axis=1\n    )\n\n    return df\n\n# Load and prepare data\ndef load_and_prepare_data(config):\n    import duckdb\n\n    train_path = '/kaggle/input/leash-BELKA/train.parquet'\n    con = duckdb.connect()\n\n    df = con.query(f\"\"\"\n        (SELECT *\n         FROM parquet_scan('{train_path}')\n         WHERE binds = 0\n         ORDER BY random()\n         LIMIT {config['num_samples_per_class']})\n        UNION ALL\n        (SELECT *\n         FROM parquet_scan('{train_path}')\n         WHERE binds = 1\n         ORDER BY random()\n         LIMIT {config['num_samples_per_class']})\n    \"\"\").df()\n\n    con.close()\n\n    # Combine SMILES strings\n    df['combined_smiles'] = df['molecule_smiles'] + ' ' + df['buildingblock1_smiles'] + ' ' + df['buildingblock2_smiles'] + ' ' + df['buildingblock3_smiles']\n\n    # One-hot encode the protein_name\n    onehot_encoder = OneHotEncoder(sparse_output=False)\n    protein_onehot = onehot_encoder.fit_transform(df[['protein_name']])\n    df['protein_onehot'] = list(protein_onehot)\n\n    # Convert SMILES to RDKit molecules\n    df['molecule'] = df['molecule_smiles'].apply(Chem.MolFromSmiles)\n\n    # Generate ECFPs\n    df['ecfp'] = df['molecule'].apply(lambda x: generate_ecfp(x, config['ecfp_radius'], config['ecfp_bits']))\n\n    return df, onehot_encoder\n\n# Load and prepare data\ndf, onehot_encoder = load_and_prepare_data(config)\n\n# Load pre-trained models and tokenizer\nmf_tokenizer = AutoTokenizer.from_pretrained(config['molformer_model_name'], deterministic_eval=True, trust_remote_code=True)\nmf_model = AutoModelForSequenceClassification.from_pretrained(config['molformer_model_name'], num_labels=2, trust_remote_code=True)\nmf_model.eval()\n\n# Move the model to the device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmf_model.to(device)\n\n# Generate features for the training data\ndf = generate_features(df, onehot_encoder, config, mf_tokenizer, mf_model, device)\n\n# Prepare vector search and RAG features\ndef prepare_vector_search_and_rag_features(df, config):\n    # Convert to list of feature vectors for modeling\n    X = df['hybrid_embeddings'].tolist()\n    y = df['binds'].tolist() if 'binds' in df.columns else None\n\n    # Convert hybrid embeddings to numpy array and ensure float32 type\n    hybrid_embeddings = np.vstack(df['hybrid_embeddings'].values).astype(np.float32)\n\n    # Normalize embeddings\n    faiss.normalize_L2(hybrid_embeddings)\n\n    # Initialize FAISS index with GPU\n    d = hybrid_embeddings.shape[1]  # Dimension of the embeddings\n    res = faiss.StandardGpuResources() if config['use_gpu_for_faiss'] else None\n    index = faiss.IndexFlatL2(d)  # Index for flat (exact) L2 distance\n    if res:\n        gpu_index = faiss.index_cpu_to_gpu(res, 0, index)  # Move index to GPU\n    else:\n        gpu_index = index\n\n    # Add embeddings to the index\n    gpu_index.add(hybrid_embeddings)\n\n    # Retrieve the top k nearest neighbors for each embedding\n    k = 5  # Number of nearest neighbors to retrieve\n    D, I = gpu_index.search(hybrid_embeddings, k)\n\n    # Apply attention mechanism and weighted averaging\n    def apply_attention_and_weighted_averaging(embeddings, neighbors_idx, distances):\n        augmented_embeddings = []\n        for i, (neighbors, dist) in enumerate(zip(neighbors_idx, distances)):\n            neighbor_embeddings = embeddings[neighbors]\n\n            # Calculate attention weights\n            similarities = 1 / (dist + 1e-6)\n            attention_weights = torch.softmax(torch.tensor(similarities), dim=0).numpy()\n\n            # Weighted averaging of neighbor embeddings\n            weighted_average = np.average(neighbor_embeddings, axis=0, weights=attention_weights)\n\n            # Combine the original embedding with the weighted average of neighbors\n            final_embedding = np.concatenate([embeddings[i], weighted_average])\n            augmented_embeddings.append(final_embedding)\n\n        return np.array(augmented_embeddings)\n\n    final_feature_vectors = apply_attention_and_weighted_averaging(hybrid_embeddings, I, D)\n\n    return final_feature_vectors, np.array(y) if y else None  # Convert y to numpy array if available\n\n# Prepare vector search and RAG features for training\nX_final, y = prepare_vector_search_and_rag_features(df, config)\n\n# Train the first ensemble model\ndef train_first_ensemble_model(X_final, y, config):\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    \n    # Store metrics\n    all_metrics = []\n    \n    for train_index, test_index in skf.split(X_final, y):\n        X_train, X_test = X_final[train_index], X_final[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        \n        # Train individual models\n        rf_model = RandomForestClassifier(**config['rf_params'])\n\n        # Ensure 'use_label_encoder' and 'eval_metric' are not in config['xgb_params']\n        xgb_params = {k: v for k, v in config['xgb_params'].items() if k not in ['use_label_encoder', 'eval_metric', 'early_stopping_rounds']}\n        xgb_model = XGBClassifier(tree_method='hist', use_label_encoder=False, eval_metric='logloss', **xgb_params)\n\n        xgb_model.fit(X_train, y_train)\n        rf_model.fit(X_train, y_train)\n\n        # Ensemble model\n        ensemble_model = VotingClassifier(estimators=[\n            ('rf', rf_model), ('xgb', xgb_model)\n        ], voting='soft')\n\n        ensemble_model.fit(X_train, y_train)\n\n        # Evaluate model\n        metrics = evaluate_model(ensemble_model, X_test, y_test)\n        all_metrics.append(metrics)\n    \n    # Calculate average metrics\n    avg_metrics = np.mean(all_metrics, axis=0)\n    return ensemble_model, avg_metrics\n\n# Function to evaluate the model\ndef evaluate_model(model, features, labels):\n    predictions = model.predict(features)\n    prob_predictions = model.predict_proba(features)[:, 1]\n    roc_auc = roc_auc_score(labels, prob_predictions)\n    accuracy = accuracy_score(labels, predictions)\n    f1 = f1_score(labels, predictions, average='macro')\n    return roc_auc, accuracy, f1\n\n# Train the first ensemble model\nensemble_model, avg_metrics = train_first_ensemble_model(X_final, y, config)\nprint(f\"First Ensemble Average Metrics: ROC AUC: {avg_metrics[0]}, Accuracy: {avg_metrics[1]}, F1 Score: {avg_metrics[2]}\")\n\n# Plot learning curve\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5), ax=None):\n    if ax is None:\n        ax = plt.gca()\n\n    ax.set_title(title)\n    if ylim is not None:\n        ax.set_ylim(*ylim)\n    ax.set_xlabel(\"Training examples\")\n    ax.set_ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes\n    )\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax.grid()\n\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1,\n                    color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n\n    ax.legend(loc=\"best\")\n    return ax\n\n# Plot learning curve for the ensemble model\ncv = StratifiedKFold(n_splits=3)\nfig, ax = plt.subplots(figsize=(10, 6))\nplot_learning_curve(ensemble_model, \"First Ensemble Model Learning Curve\", X_final, y, cv=cv, ax=ax)\nplt.show()\n\n# Function to prepare test data\ndef prepare_test_data(df_test, onehot_encoder, config, tokenizer, model, device, expected_dim):\n    # Generate ECFPs for the molecule_smiles\n    df_test['molecule'] = df_test['molecule_smiles'].apply(Chem.MolFromSmiles)\n    df_test['ecfp'] = df_test['molecule'].apply(lambda x: generate_ecfp(x, config['ecfp_radius'], config['ecfp_bits']))\n\n    # One-hot encode the protein_name\n    protein_onehot = onehot_encoder.transform(df_test[['protein_name']])\n    protein_onehot_df = pd.DataFrame(protein_onehot, index=df_test.index)\n\n    # Get MolFormer embeddings for combined SMILES in batches\n    df_test['combined_smiles'] = df_test['molecule_smiles'] + ' ' + df_test['buildingblock1_smiles'] + ' ' + df_test['buildingblock2_smiles'] + ' ' + df_test['buildingblock3_smiles']\n    combined_smiles_list = df_test['combined_smiles'].tolist()\n    molformer_embeddings_list = []\n\n    for i in range(0, len(combined_smiles_list), config['batch_size']):\n        batch_smiles = combined_smiles_list[i:i + config['batch_size']]\n        molformer_embeddings_list.extend(get_molformer_embeddings_batch(batch_smiles, tokenizer, model, device))\n\n    df_test['molformer_embeddings'] = molformer_embeddings_list[:len(df_test)]\n\n    # Combine ECFPs, MolFormer embeddings, and one-hot encoded protein names\n    df_test['hybrid_embeddings'] = df_test.apply(\n        lambda row: np.concatenate([row['ecfp'], row['molformer_embeddings'].flatten(), protein_onehot_df.loc[row.name]]), axis=1\n    )\n\n    # Final feature vectors\n    hybrid_embeddings = np.vstack(df_test['hybrid_embeddings'].values).astype(np.float32)\n\n    print(f\"Test feature dimension: {hybrid_embeddings.shape[1]}\")\n\n    # Normalize embeddings\n    faiss.normalize_L2(hybrid_embeddings)\n\n    # Initialize FAISS index with GPU\n    d = hybrid_embeddings.shape[1]  # Dimension of the embeddings\n    res = faiss.StandardGpuResources() if config['use_gpu_for_faiss'] else None\n    index = faiss.IndexFlatL2(d)  # Index for flat (exact) L2 distance\n    if res:\n        gpu_index = faiss.index_cpu_to_gpu(res, 0, index)  # Move index to GPU\n    else:\n        gpu_index = index\n\n    # Add embeddings to the index\n    gpu_index.add(hybrid_embeddings)\n\n    # Retrieve the top k nearest neighbors for each embedding\n    k = 5  # Number of nearest neighbors to retrieve\n    D, I = gpu_index.search(hybrid_embeddings, k)\n\n    # Apply attention mechanism and weighted averaging\n    def apply_attention_and_weighted_averaging(embeddings, neighbors_idx, distances):\n        augmented_embeddings = []\n        for i, (neighbors, dist) in enumerate(zip(neighbors_idx, distances)):\n            neighbor_embeddings = embeddings[neighbors]\n\n            # Calculate attention weights\n            similarities = 1 / (dist + 1e-6)\n            attention_weights = torch.softmax(torch.tensor(similarities), dim=0).numpy()\n\n            # Weighted averaging of neighbor embeddings\n            weighted_average = np.average(neighbor_embeddings, axis=0, weights=attention_weights)\n\n            # Combine the original embedding with the weighted average of neighbors\n            final_embedding = np.concatenate([embeddings[i], weighted_average])\n            augmented_embeddings.append(final_embedding)\n\n        return np.array(augmented_embeddings)\n\n    final_feature_vectors = apply_attention_and_weighted_averaging(hybrid_embeddings, I, D)\n\n    # Ensure the test feature dimension matches the expected dimension\n    if final_feature_vectors.shape[1] != expected_dim:\n        raise ValueError(f\"Test data dimension {final_feature_vectors.shape[1]} does not match training data dimension {expected_dim}\")\n\n    return final_feature_vectors\n\n# Load the test data\ntest_file = '/kaggle/input/leash-BELKA/test.csv'\ndf_test_full = pd.read_csv(test_file)\ndf_test_sample = df_test_full.sample(frac=1, random_state=42).reset_index(drop=True)  # Adjust sample size for testing\n\n# Prepare test data\nhybrid_embeddings_test = prepare_test_data(df_test_sample, onehot_encoder, config, mf_tokenizer, mf_model, device, X_final.shape[1])\n\n# Generate predictions using the first ensemble model\nfirst_ensemble_predictions = ensemble_model.predict_proba(hybrid_embeddings_test)\n\n# Since the test data does not have true labels, just show predictions\nprint(\"First Ensemble Model Predictions:\")\nprint(first_ensemble_predictions)\n\n# Save the predictions to a CSV file\noutput_file = 'submission.csv'\ndf_test_sample['predictions'] = first_ensemble_predictions[:, 1]\ndf_test_sample[['id', 'predictions']].to_csv(output_file, index=False)\nprint(f\"Predictions saved to {output_file}\")\n\n# Function to generate submission\ndef generate_submission(test_file, output_file, ensemble_model, onehot_encoder, config, tokenizer, model, device):\n    # Load the test data\n    df_test_full = pd.read_csv(test_file)\n    df_test_sample = df_test_full.sample(frac=1, random_state=42)\n    df_test_full = generate_features(df_test_sample, onehot_encoder, config, tokenizer, model, device)\n    \n    hybrid_embeddings = np.vstack(df_test_full['hybrid_embeddings'].values).astype(np.float32)\n\n    # Normalize embeddings\n    faiss.normalize_L2(hybrid_embeddings)\n\n    # Initialize FAISS index with GPU\n    d = hybrid_embeddings.shape[1]  # Dimension of the embeddings\n    res = faiss.StandardGpuResources() if config['use_gpu_for_faiss'] else None\n    index = faiss.IndexFlatL2(d)  # Index for flat (exact) L2 distance\n    if res:\n        gpu_index = faiss.index_cpu_to_gpu(res, 0, index)  # Move index to GPU\n    else:\n        gpu_index = index\n\n    # Add embeddings to the index\n    gpu_index.add(hybrid_embeddings)\n\n    # Retrieve the top k nearest neighbors for each embedding\n    k = 5  # Number of nearest neighbors to retrieve\n    D, I = gpu_index.search(hybrid_embeddings, k)\n\n    # Apply attention mechanism and weighted averaging\n    def apply_attention_and_weighted_averaging(embeddings, neighbors_idx, distances):\n        augmented_embeddings = []\n        for i, (neighbors, dist) in enumerate(zip(neighbors_idx, distances)):\n            neighbor_embeddings = embeddings[neighbors]\n\n            # Calculate attention weights\n            similarities = 1 / (dist + 1e-6)\n            attention_weights = torch.softmax(torch.tensor(similarities), dim=0).numpy()\n\n            # Weighted averaging of neighbor embeddings\n            weighted_average = np.average(neighbor_embeddings, axis=0, weights=attention_weights)\n\n            # Combine the original embedding with the weighted average of neighbors\n            final_embedding = np.concatenate([embeddings[i], weighted_average])\n            augmented_embeddings.append(final_embedding)\n\n        return np.array(augmented_embeddings)\n\n    final_feature_vectors = apply_attention_and_weighted_averaging(hybrid_embeddings, I, D)\n\n    # Generate predictions using the first ensemble model\n    first_ensemble_predictions = ensemble_model.predict_proba(final_feature_vectors)[:, 1]\n\n    # Run basic QC checks on the predictions\n    if not pd.api.types.is_numeric_dtype(first_ensemble_predictions):\n        raise ValueError('All submission values must be numeric')\n\n    if not np.isfinite(first_ensemble_predictions).all():\n        raise ValueError('All submission values must be finite')\n\n    if first_ensemble_predictions.min() < 0:\n        raise ValueError('All submission values must be at least zero')\n\n    if first_ensemble_predictions.max() > 1:\n        raise ValueError('All submission values must be no greater than one')\n\n    # Create a DataFrame with 'id' and 'binds' columns\n    output_df = pd.DataFrame({'id': df_test_full['id'], 'binds': first_ensemble_predictions})\n\n    # Save predictions to CSV\n    output_df.to_csv(output_file, index=False)\n    print(\"Submission file generated successfully.\")\n\n# Generate submission\ngenerate_submission(test_file, output_file, ensemble_model, onehot_encoder, config, mf_tokenizer, mf_model, device)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T05:03:54.245998Z","iopub.execute_input":"2024-07-07T05:03:54.246389Z","iopub.status.idle":"2024-07-07T05:06:47.268458Z","shell.execute_reply.started":"2024-07-07T05:03:54.246359Z","shell.execute_reply":"2024-07-07T05:06:47.267526Z"},"trusted":true},"execution_count":null,"outputs":[]}]}